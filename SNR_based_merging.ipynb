{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/elemannoni/SNR-based-Selective-Model-Merging.git\n",
        "%cd SNR-based-Selective-Model-Merging"
      ],
      "metadata": {
        "id": "hJqHPSChUnBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOpz6Ydw48Ck"
      },
      "source": [
        "## Importazione librerie utili"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9HwMnICQkvjB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Subset, Dataset\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "import tracemalloc\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "from copy import deepcopy\n",
        "from sklearn.metrics import f1_score\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Pg3-KUrLpan"
      },
      "source": [
        "## Preparazione Pytorch e modello"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWc1acBw4saT",
        "outputId": "a8f7fdf3-fe50-46fc-b5bc-357fe12444f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Utilizza il dispositivo: cuda\n"
          ]
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Utilizza il dispositivo: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FK6qQOOnLpan"
      },
      "outputs": [],
      "source": [
        "from src.model import CNN_snr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nF2UqMrdLpao"
      },
      "source": [
        "## Dataset e dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8jlv9FpMYos",
        "outputId": "7ddc72fb-4100-45b9-90d2-1dca527b3b08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creato dataset di training A con 20000 campioni.\n",
            "Creato dataset di training B con 30000 campioni.\n",
            "Creato dataset di test A con 4000 campioni.\n",
            "Creato dataset di test B con 6000 campioni.\n"
          ]
        }
      ],
      "source": [
        "from src.dataset import create_dataloader_CIFAR10\n",
        "loader_A, loader_B, test_loader_A, test_loader_B, loader_full_train, loader_full_test = create_dataloader_CIFAR10(batch_size = 1024)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-BVQDjd5Dd4"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "D45i2H7kk_qL",
        "outputId": "7611087d-0aef-47e2-8ce9-7c6a27f3ded9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Addestramento Modello Base (Baseline) ---\n",
            "Inizio addestramento per 5 epoche...\n",
            "Epoch 1/5 -> Loss: 1.6527, Accuracy sul Test Set: 44.12%, F1-Score: 39.35%\n",
            "Epoch 2/5 -> Loss: 1.1122, Accuracy sul Test Set: 57.65%, F1-Score: 56.29%\n",
            "Epoch 3/5 -> Loss: 0.8551, Accuracy sul Test Set: 67.99%, F1-Score: 68.11%\n",
            "Epoch 4/5 -> Loss: 0.7052, Accuracy sul Test Set: 73.33%, F1-Score: 73.08%\n",
            "Epoch 5/5 -> Loss: 0.5880, Accuracy sul Test Set: 73.75%, F1-Score: 74.11%\n",
            "Addestramento completato.\n",
            "--- Addestramento Modello A (Esperto) ---\n",
            "Pesi del corpo trasferiti da backbone a esperto (output_size=4).\n",
            "Inizio addestramento per 5 epoche...\n",
            "Epoch 1/5 -> Loss: 1.1281, Accuracy sul Test Set: 80.92%, F1-Score: 80.93%\n",
            "Epoch 2/5 -> Loss: 0.4138, Accuracy sul Test Set: 91.12%, F1-Score: 91.11%\n",
            "Epoch 3/5 -> Loss: 0.1824, Accuracy sul Test Set: 91.45%, F1-Score: 91.43%\n",
            "Epoch 4/5 -> Loss: 0.1040, Accuracy sul Test Set: 92.42%, F1-Score: 92.42%\n",
            "Epoch 5/5 -> Loss: 0.0643, Accuracy sul Test Set: 92.17%, F1-Score: 92.18%\n",
            "Addestramento completato.\n",
            "\n",
            "--- Addestramento Modello B (Esperto) ---\n",
            "Pesi del corpo trasferiti da backbone a esperto (output_size=6).\n",
            "Inizio addestramento per 5 epoche...\n",
            "Epoch 1/5 -> Loss: 1.0330, Accuracy sul Test Set: 76.45%, F1-Score: 76.43%\n",
            "Epoch 2/5 -> Loss: 0.4639, Accuracy sul Test Set: 79.97%, F1-Score: 80.00%\n",
            "Epoch 3/5 -> Loss: 0.3050, Accuracy sul Test Set: 79.50%, F1-Score: 79.43%\n",
            "Epoch 4/5 -> Loss: 0.2136, Accuracy sul Test Set: 79.75%, F1-Score: 79.85%\n",
            "Epoch 5/5 -> Loss: 0.1590, Accuracy sul Test Set: 78.88%, F1-Score: 78.83%\n",
            "Addestramento completato.\n"
          ]
        }
      ],
      "source": [
        "from src.train_and_evaluation import train_model\n",
        "from utils import transfer_body_weights\n",
        "\n",
        "\n",
        "print(\"--- Addestramento Modello Base (Baseline) ---\")\n",
        "model = CNN_snr(output_size=10)\n",
        "model.to(device)\n",
        "train_model(model, loader_full_train, loader_full_test, device, epochs=5, lr=0.005)\n",
        "\n",
        "print(\"--- Addestramento Modello A (Esperto) ---\")\n",
        "model_A = CNN_snr(output_size=len(A_indices))\n",
        "transfer_body_weights(model, model_A)\n",
        "model_A.to(device)\n",
        "train_model(model_A, loader_A, test_loader_A, device, epochs=5)\n",
        "\n",
        "print(\"\\n--- Addestramento Modello B (Esperto) ---\")\n",
        "model_B = CNN_snr(output_size=len(B_indices))\n",
        "transfer_body_weights(model, model_B)\n",
        "model_B.to(device)\n",
        "train_model(model_B, loader_B, test_loader_B, device, epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ke57zGg45JJ2"
      },
      "source": [
        "## Allineamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5S001nkDHzWt"
      },
      "source": [
        "Per fare merging tra due modelli non si può semplicemente mediare i loro pesi. Due modelli differenti infatti, anche se svolgono lo stesso compito, potrebbero aver imparato le stesse feature in un ordine completamente diverso. Questo disallineamento è dato dalla **simmetria delle permutazioni**: una proprietà delle reti neurali per cui è possibile scambiare l'ordine dei neuroni in un layer (riorninandone poi le connessioni nel layer successivo) senza alterare l'output della rete.\n",
        "\n",
        "\n",
        "L'algoritmo di **Git-Rebasin** (descritto nel paper https://arxiv.org/abs/2209.04836) risolve questo problema cercando una **permutazione ottimale** che riallinea i neuroni dei due modelli.\n",
        "\n",
        "In particolare, l'algoritmo implementato:\n",
        "* **Calcola la Matrice dei Costi:** dato un layer, calcola il costo per associare ogni neurone di $A$ con ogni neurone di $B$ tramite la distanza $L_2$.\n",
        "* **Trova la Permutazione Ottimale:** Usa l'*Algoritmo Ungherese* (linear_sum_assignment) per minimizzare il costo totale e trovare quindi la matrice di permutazione $P$.\n",
        "* **Applica la Permutazione:** Applica $W'_i = P * W_i$ e poi $W'_{i+1} = W_{i+1} * P^{-1}$ al layer successivo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhzzcLZGPQeD"
      },
      "outputs": [],
      "source": [
        "from src.utils import git_rebasin_align\n",
        "aligned_model_B = git_rebasin_align(model, model_B, device)\n",
        "aligned_model_A = git_rebasin_align(model, model_A, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMhdbhLgLpap"
      },
      "source": [
        "Testiamo la consistenza ciclica dell'allineamento. Ci si aspetta una perdita bassa per modelli ben allineati."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePOFdg2r2vXa",
        "outputId": "71a64b2f-8ce6-4098-d6e3-a379cdf74cc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Allineamento completato (stile Git-Rebasin).\n",
            "Allineamento completato (stile Git-Rebasin).\n",
            "Allineamento completato (stile Git-Rebasin).\n",
            "Allineamento completato (stile Git-Rebasin).\n",
            "Perdita di Coerenza Ciclica A: 0.0\n",
            "Perdita di Coerenza Ciclica B: 0.0\n"
          ]
        }
      ],
      "source": [
        "from src.utils import cycle_consistency\n",
        "cycle_consistency(model, model_A, model_B)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fshg2TyLpap"
      },
      "source": [
        "Verifichiamo che l'allineamento abbia apportato modifiche. Infatti avendo due modelli specializzati inizializzati dallo stesso modello, potrebbero essere giá allineati in partenza (l'algoritmo di allineamento non effettua modifiche in questo caso)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__TkPiPtLpap",
        "outputId": "37e701d2-671b-49a2-a66b-c798f517e3a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "L'allineamento ha lasciato model_B invariato? -> True\n",
            "L'allineamento ha lasciato model_A invariato? -> True\n"
          ]
        }
      ],
      "source": [
        "from src.utils import check_models_identical\n",
        "\n",
        "is_alignment_B = check_models_identical(model_B, aligned_model_B)\n",
        "print(f\"L'allineamento ha lasciato model_B invariato? -> {is_alignment_B}\")\n",
        "\n",
        "is_alignment_A = check_models_identical(model_A, aligned_model_A)\n",
        "print(f\"L'allineamento ha lasciato model_A invariato? -> {is_alignment_A}\")\n",
        "\n",
        "is_alignment_noop = is_alignment_A and is_alignment_B"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3n_Kdeg5PGG"
      },
      "source": [
        "## SNR e merge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUOSydweLpap"
      },
      "source": [
        "Si calcola il Signal-to-Noise Ratio (SNR) per ogni layer di entrambi i modelli allineati secondo quanto descritto nel paper [Spectrum: Targeted Training on Signal to Noise Ratio](https://arxiv.org/abs/2406.06623). I layer con SNR più alto sono considerati più \"importanti\" e saranno quelli selezionati per il merging."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNVrvO2NlFxN"
      },
      "outputs": [],
      "source": [
        "from src.SNR import calculate_snr\n",
        "\n",
        "\n",
        "snr_scores = {'model_A': [], 'model_B': [], 'model': []}\n",
        "for layer in model_A.layers:\n",
        "  snr_scores['model_A'].append(calculate_snr(layer.weight))\n",
        "\n",
        "for layer in aligned_model_B.layers:\n",
        "  snr_scores['model_B'].append(calculate_snr(layer.weight))\n",
        "\n",
        "for layer in model.layers:\n",
        "    snr_scores['model'].append(calculate_snr(layer.weight))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rkn8yoTXLpaq"
      },
      "source": [
        "## Merging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWsliU9TLpaq"
      },
      "source": [
        "Si implementa una funzione che permette di fare *merging* dei modelli considerando solo i layer più \"importanti\" classificandoli secondo il loro SNR. I layer restanti vengono copiati da un modello di riferimento. <br>\n",
        "Il merging avviene sfruttando 3 diverse tecniche.<br>\n",
        "- **LERP**: Consiste nel calcolare una media pesata dei parametri (pesi e bias) dei due modelli.\n",
        "- **SLERP**: Questa tecnica interpola i parametri lungo un arco di cerchio su un'ipersfera.\n",
        "- **TIES**: Tecnica che mira a risolvere le \"interferenze\" tra i parametri appresi dai due modelli fondendo solo quelli che hanno appreso nella stessa direzione rispetto a un modello di partenza. Paper di riferimento: [TIES-Merging: Resolving Interference When Merging Models](https://arxiv.org/abs/2306.01708)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hSzYoUoSlJUl"
      },
      "outputs": [],
      "source": [
        "from src.merge import merge_models_top_p\n",
        "\n",
        "\n",
        "indices_merged_10, merged_model_10 = merge_models_top_p(\n",
        "    aligned_model_A, aligned_model_B, deepcopy(model),\n",
        "    snr_scores['model_A'], snr_scores['model_B'], snr_scores['model'], top_p=0.10\n",
        ")\n",
        "\n",
        "indices_merged_15, merged_model_15 = merge_models_top_p(\n",
        "    aligned_model_A, aligned_model_B, deepcopy(model),\n",
        "    snr_scores['model_A'], snr_scores['model_B'], snr_scores['model'], top_p=0.15\n",
        ")\n",
        "\n",
        "indices_merged_avg_snr, merged_model_avg_snr = merge_models_top_p(\n",
        "    aligned_model_A, aligned_model_B, deepcopy(model),\n",
        "    snr_scores['model_A'], snr_scores['model_B'], snr_scores['model'], top_p=0.15, snr_avg=True\n",
        ")\n",
        "\n",
        "indices_merged_slerp_10, merged_model_slerp_10 = merge_models_top_p(\n",
        "    aligned_model_A, aligned_model_B, deepcopy(model),\n",
        "    snr_scores['model_A'], snr_scores['model_B'], snr_scores['model'], top_p=0.10, merge_method='slerp'\n",
        ")\n",
        "\n",
        "indices_merged_slerp_15, merged_model_slerp_15 = merge_models_top_p(\n",
        "    aligned_model_A, aligned_model_B, deepcopy(model),\n",
        "    snr_scores['model_A'], snr_scores['model_B'], snr_scores['model'], top_p=0.15, merge_method='slerp'\n",
        ")\n",
        "\n",
        "indices_merged_ties_10, merged_model_ties_10 = merge_models_top_p(\n",
        "    aligned_model_A, aligned_model_B, deepcopy(model),\n",
        "    snr_scores['model_A'], snr_scores['model_B'], snr_scores['model'], top_p=0.10, merge_method='ties'\n",
        ")\n",
        "\n",
        "indices_merged_ties_15, merged_model_ties_15 = merge_models_top_p(\n",
        "    aligned_model_A, aligned_model_B, deepcopy(model),\n",
        "    snr_scores['model_A'], snr_scores['model_B'], snr_scores['model'], top_p=0.15, merge_method='ties'\n",
        ")\n",
        "\n",
        "all_indices_lerp , merged_model_lerp = merge_models_top_p(\n",
        "    aligned_model_A, aligned_model_B, deepcopy(model),\n",
        "    snr_scores['model_A'], snr_scores['model_B'], snr_scores['model'], top_p = 1\n",
        ")\n",
        "\n",
        "all_indices_slerp , merged_model_slerp = merge_models_top_p(\n",
        "    aligned_model_A, aligned_model_B, deepcopy(model),\n",
        "    snr_scores['model_A'], snr_scores['model_B'], snr_scores['model'], top_p = 1, merge_method='slerp'\n",
        ")\n",
        "\n",
        "all_indices_ties , merged_model_ties = merge_models_top_p(\n",
        "    aligned_model_A, aligned_model_B, deepcopy(model),\n",
        "    snr_scores['model_A'], snr_scores['model_B'], snr_scores['model'], top_p = 1, merge_method='ties'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKWgxK5gLpaq"
      },
      "source": [
        "## Consistenza post-merging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nyhXk2JLpaq"
      },
      "source": [
        "\n",
        "Si esegue un'analisi di consistenza basata sull'aritmetica dei task vector descritta nel paper [Editing Models with Task Arithmetic](https://arxiv.org/abs/2212.04089). Si calcola la \"direzione\" dei modelli rispetto a un modello di riferimento per capire se dopo il merging il nuovo modello si trova dove ci si attendeva.<br>\n",
        "- Valori positivi e intorno ad 1 indicano una forte somiglianza tra il valore atteso e quello ottenuto.\n",
        "- Valori intorno a 0 indicano una scarsa vicinanza al valore atteso e quindi il modello dopo il merging non ha acquisito conoscenza di task aggiuntive.\n",
        "- Valori vicino a -1 indicano che il merging é stato distruttivo rispetto ad alcune task.<br>\n",
        "Non avendo eseguito il merging su tutti i layer ci si aspettano valori scarsi o negativi se il test é eseguito sui modelli completi. Analizzando solo il layer fusi ci si aspetta di vedere risultati coerenti con la accuratezza del modello ad eseguire determinate task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gzy-pQSYLpaq",
        "outputId": "0daa3f64-1e10-43ca-8c49-d82dafc25d0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "RIEPILOGO CONSISTENZA (TUTTI I LAYER)\n",
            "==================================================\n",
            "                     consistency_A consistency_B avg_consistency\n",
            "Full LERP                   0.9240       -0.8277          0.0481\n",
            "Full SLERP                  0.9240       -0.8277          0.0481\n",
            "Linear 15%                  0.9240       -0.8278          0.0481\n",
            "Linear 15% (SNR Avg)        0.9240       -0.8278          0.0481\n",
            "SLERP 15%                   0.9240       -0.8278          0.0481\n",
            "Linear 10%                  0.9240       -0.8278          0.0481\n",
            "TIES 10%                    0.9240       -0.8278          0.0481\n",
            "SLERP 10%                   0.9240       -0.8278          0.0481\n",
            "TIES 15%                    0.9240       -0.8278          0.0481\n",
            "Full TIES                   0.9240       -0.8278          0.0481\n",
            "\n",
            "==================================================\n",
            "RIEPILOGO CONSISTENZA (SOLO LAYER FUSI)\n",
            "==================================================\n",
            "                     consistency_A consistency_B avg_consistency\n",
            "Linear 15% (SNR Avg)        1.0000        1.0000          1.0000\n",
            "Linear 10%                  1.0000        1.0000          1.0000\n",
            "Linear 15%                  1.0000        1.0000          1.0000\n",
            "SLERP 15%                   0.9997        0.9997          0.9997\n",
            "SLERP 10%                   0.9997        0.9997          0.9997\n",
            "TIES 10%                    0.9258        0.9198          0.9228\n",
            "TIES 15%                    0.9261        0.9179          0.9220\n",
            "Full LERP                   0.9240       -0.8277          0.0481\n",
            "Full SLERP                  0.9240       -0.8277          0.0481\n",
            "Full TIES                   0.9240       -0.8278          0.0481\n"
          ]
        }
      ],
      "source": [
        "from src.utils import calculate_delta, perform_consistency_analysis, print_summary\n",
        "\n",
        "analysis_targets = [\n",
        "    {\"name\": \"LERP 10%\", \"model\": merged_model_10, \"indices\": indices_merged_10},\n",
        "    {\"name\": \"LERP 15%\", \"model\": merged_model_15, \"indices\": indices_merged_15},\n",
        "    {\"name\": \"LERP 15% (SNR Avg)\", \"model\": merged_model_avg_snr, \"indices\": indices_merged_avg_snr},\n",
        "    {\"name\": \"SLERP 10%\", \"model\": merged_model_slerp_10, \"indices\": indices_merged_slerp_10},\n",
        "    {\"name\": \"SLERP 15%\", \"model\": merged_model_slerp_15, \"indices\": indices_merged_slerp_15},\n",
        "    {\"name\": \"TIES 10%\", \"model\": merged_model_ties_10, \"indices\": indices_merged_ties_10},\n",
        "    {\"name\": \"TIES 15%\", \"model\": merged_model_ties_15, \"indices\": indices_merged_ties_15},\n",
        "    {\"name\": \"Full LERP\", \"model\": merged_model_lerp, \"indices\": all_indices_lerp},\n",
        "    {\"name\": \"Full SLERP\", \"model\": merged_model_slerp, \"indices\": all_indices_slerp},\n",
        "    {\"name\": \"Full TIES\", \"model\": merged_model_ties, \"indices\": all_indices_ties},\n",
        "]\n",
        "\n",
        "#Preparazione dei Delta di Base\n",
        "base_model_ref = model\n",
        "expert_A = aligned_model_A\n",
        "expert_B = aligned_model_B\n",
        "LAYER_NAME_TO_IGNORE = 'output'\n",
        "\n",
        "delta_A_full = calculate_delta(expert_A, base_model_ref, layer_to_ignore=LAYER_NAME_TO_IGNORE)\n",
        "delta_B_full = calculate_delta(expert_B, base_model_ref, layer_to_ignore=LAYER_NAME_TO_IGNORE)\n",
        "\n",
        "\n",
        "total_consistency_results = {}\n",
        "for target in analysis_targets:\n",
        "    name = target[\"name\"]\n",
        "    merged_model = target[\"model\"]\n",
        "\n",
        "    delta_merged_full = calculate_delta(merged_model, base_model_ref, layer_to_ignore=LAYER_NAME_TO_IGNORE)\n",
        "\n",
        "    consistency_A, consistency_B, avg_consistency = perform_consistency_analysis(\n",
        "        delta_A_full, delta_B_full, delta_merged_full\n",
        "    )\n",
        "\n",
        "    total_consistency_results[name] = {\n",
        "        'consistency_A': consistency_A, 'consistency_B': consistency_B, 'avg_consistency': avg_consistency\n",
        "    }\n",
        "\n",
        "\n",
        "selective_consistency_results = {}\n",
        "all_param_keys = delta_A_full.keys()\n",
        "\n",
        "for target in analysis_targets:\n",
        "    name = target[\"name\"]\n",
        "    merged_model = target[\"model\"]\n",
        "    merged_indices = target[\"indices\"]\n",
        "\n",
        "    #Nomi dei parametri corrispondenti agli indici\n",
        "    keys_to_analyze = {k for k in all_param_keys if any(k.startswith(f\"layers.{idx}.\") for idx in merged_indices)}\n",
        "\n",
        "    if not keys_to_analyze:\n",
        "        continue\n",
        "\n",
        "    #Filtro dei delta\n",
        "    delta_A_filtered = {k: v for k, v in delta_A_full.items() if k in keys_to_analyze}\n",
        "    delta_B_filtered = {k: v for k, v in delta_B_full.items() if k in keys_to_analyze}\n",
        "    delta_merged_full = calculate_delta(merged_model, base_model_ref, layer_to_ignore=LAYER_NAME_TO_IGNORE)\n",
        "    delta_merged_filtered = {k: v for k, v in delta_merged_full.items() if k in keys_to_analyze}\n",
        "\n",
        "    consistency_A, consistency_B, avg_consistency = perform_consistency_analysis(\n",
        "        delta_A_filtered, delta_B_filtered, delta_merged_filtered\n",
        "    )\n",
        "\n",
        "    selective_consistency_results[name] = {\n",
        "        'consistency_A': consistency_A, 'consistency_B': consistency_B, 'avg_consistency': avg_consistency\n",
        "    }\n",
        "\n",
        "print_summary(\"CONSISTENZA: TUTTI I LAYER\", total_consistency_results)\n",
        "print_summary(\"CONSISTENZA: SOLO LAYER FUSI\", selective_consistency_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3uaTMmd5Vqx"
      },
      "source": [
        "## Fine-tuning e risultati"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Lhcqep2Lpaq"
      },
      "source": [
        "É necessario verificare come si comportano i nuovi modelli. Per seguire quanto descritto nel paper di riferimento, si \"congelano\" alcuni layer per addestrare solo quelli interessati dal merging (e necessariamente anche l'output layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZOGLKnOoLpar"
      },
      "outputs": [],
      "source": [
        "from src.utils import freeze_layers_selectively"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCkO3fMmLpar"
      },
      "source": [
        "Si calcolano accuratezza e F1-Score prima e dopo il fine-tuning del modello baseline, di un modello con merging non allineato (se l'allineamento ha senso) e di tutti i modelli fusi. Questi ultimi vengono addestrati congelando tutti i layer eccetto quello di output, congelando tutti i layer non selezionati in base all'SNR e senza congelamenti. Un'accuratezza o F1-score inferiore al modello baseline prima del fine-tuning indica un modello poco efficace. Ci si aspetta di migliorare le metriche di valutazione con i modelli addestrati senza congelamenti. Si auspica in metriche comparabili o superiori al modello baseline fine-tuned per quanto riguarda i modelli addestrati con layer congelati, a fronte di picchi di memoria e tempi di addestramento piú bassi."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDHi77XsLpar",
        "outputId": "30db1a40-60f1-4f79-947d-8ad8a0d72bcb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test: Fine-Tuning del Modello Base (No-Merge)...\n",
            "Inizio addestramento per 10 epoche...\n",
            "Epoch 1/10 -> Loss: 0.4518, Accuracy sul Test Set: 81.16%, F1-Score: 81.13%\n",
            "Epoch 2/10 -> Loss: 0.4088, Accuracy sul Test Set: 81.77%, F1-Score: 81.73%\n",
            "Epoch 3/10 -> Loss: 0.3830, Accuracy sul Test Set: 82.13%, F1-Score: 82.13%\n",
            "Epoch 4/10 -> Loss: 0.3632, Accuracy sul Test Set: 82.26%, F1-Score: 82.24%\n",
            "Epoch 5/10 -> Loss: 0.3473, Accuracy sul Test Set: 82.37%, F1-Score: 82.35%\n",
            "Epoch 6/10 -> Loss: 0.3353, Accuracy sul Test Set: 82.47%, F1-Score: 82.45%\n",
            "Epoch 7/10 -> Loss: 0.3226, Accuracy sul Test Set: 82.57%, F1-Score: 82.57%\n",
            "Epoch 8/10 -> Loss: 0.3096, Accuracy sul Test Set: 82.61%, F1-Score: 82.61%\n",
            "Epoch 9/10 -> Loss: 0.2977, Accuracy sul Test Set: 82.62%, F1-Score: 82.61%\n",
            "Epoch 10/10 -> Loss: 0.2863, Accuracy sul Test Set: 82.76%, F1-Score: 82.75%\n",
            "Addestramento completato.\n",
            "\n",
            "Test: Fusione Naive (Senza Allineamento)...\n",
            "L'allineamento non ha modificato i pesi di model_B quindi testare il modello non allineato non ha senso.\n",
            "\n",
            "--- Analisi: Merged Linear 10% (Only Head) ---\n",
            "Accuratezza Zero-Shot: 75.39%, F1-Score: 76.18%\n",
            "Strategia: Fine-tuning solo della testa (head).\n",
            "Inizio addestramento per 10 epoche...\n",
            "Epoch 1/10 -> Loss: 0.4777, Accuracy sul Test Set: 79.14%, F1-Score: 79.08%\n",
            "Epoch 2/10 -> Loss: 0.4781, Accuracy sul Test Set: 79.26%, F1-Score: 79.20%\n",
            "Epoch 3/10 -> Loss: 0.4744, Accuracy sul Test Set: 79.30%, F1-Score: 79.25%\n",
            "Epoch 4/10 -> Loss: 0.4730, Accuracy sul Test Set: 79.34%, F1-Score: 79.28%\n",
            "Epoch 5/10 -> Loss: 0.4742, Accuracy sul Test Set: 79.41%, F1-Score: 79.36%\n",
            "Epoch 6/10 -> Loss: 0.4715, Accuracy sul Test Set: 79.34%, F1-Score: 79.28%\n",
            "Epoch 7/10 -> Loss: 0.4696, Accuracy sul Test Set: 79.43%, F1-Score: 79.37%\n",
            "Epoch 8/10 -> Loss: 0.4718, Accuracy sul Test Set: 79.40%, F1-Score: 79.35%\n",
            "Epoch 9/10 -> Loss: 0.4690, Accuracy sul Test Set: 79.36%, F1-Score: 79.30%\n",
            "Epoch 10/10 -> Loss: 0.4734, Accuracy sul Test Set: 79.32%, F1-Score: 79.23%\n",
            "Addestramento completato.\n",
            "\n",
            "--- Analisi: Merged Linear 10% (Selective FT) ---\n",
            "Accuratezza Zero-Shot: 75.39%, F1-Score: 76.18%\n",
            "Strategia: Fine-tuning selettivo (layer non fusi + testa).\n",
            "Inizio addestramento per 10 epoche...\n",
            "Epoch 1/10 -> Loss: 0.4734, Accuracy sul Test Set: 79.64%, F1-Score: 79.58%\n",
            "Epoch 2/10 -> Loss: 0.4600, Accuracy sul Test Set: 80.02%, F1-Score: 79.96%\n",
            "Epoch 3/10 -> Loss: 0.4545, Accuracy sul Test Set: 80.03%, F1-Score: 79.95%\n",
            "Epoch 4/10 -> Loss: 0.4445, Accuracy sul Test Set: 80.26%, F1-Score: 80.20%\n",
            "Epoch 5/10 -> Loss: 0.4387, Accuracy sul Test Set: 80.40%, F1-Score: 80.33%\n",
            "Epoch 6/10 -> Loss: 0.4311, Accuracy sul Test Set: 80.45%, F1-Score: 80.36%\n",
            "Epoch 7/10 -> Loss: 0.4254, Accuracy sul Test Set: 80.63%, F1-Score: 80.55%\n",
            "Epoch 8/10 -> Loss: 0.4236, Accuracy sul Test Set: 80.74%, F1-Score: 80.68%\n",
            "Epoch 9/10 -> Loss: 0.4199, Accuracy sul Test Set: 80.79%, F1-Score: 80.72%\n",
            "Epoch 10/10 -> Loss: 0.4163, Accuracy sul Test Set: 80.87%, F1-Score: 80.82%\n",
            "Addestramento completato.\n",
            "\n",
            "--- Analisi: Merged Linear 10% (Full FT) ---\n",
            "Accuratezza Zero-Shot: 75.39%, F1-Score: 76.18%\n",
            "Strategia: Fine-tuning completo (nessun layer congelato).\n",
            "Inizio addestramento per 10 epoche...\n",
            "Epoch 1/10 -> Loss: 0.4276, Accuracy sul Test Set: 81.83%, F1-Score: 81.80%\n",
            "Epoch 2/10 -> Loss: 0.3685, Accuracy sul Test Set: 82.17%, F1-Score: 82.17%\n",
            "Epoch 3/10 -> Loss: 0.3379, Accuracy sul Test Set: 82.33%, F1-Score: 82.33%\n",
            "Epoch 4/10 -> Loss: 0.3134, Accuracy sul Test Set: 82.53%, F1-Score: 82.51%\n",
            "Epoch 5/10 -> Loss: 0.2918, Accuracy sul Test Set: 82.68%, F1-Score: 82.67%\n",
            "Epoch 6/10 -> Loss: 0.2723, Accuracy sul Test Set: 82.58%, F1-Score: 82.59%\n",
            "Epoch 7/10 -> Loss: 0.2544, Accuracy sul Test Set: 82.61%, F1-Score: 82.60%\n",
            "Epoch 8/10 -> Loss: 0.2352, Accuracy sul Test Set: 82.69%, F1-Score: 82.69%\n",
            "Epoch 9/10 -> Loss: 0.2173, Accuracy sul Test Set: 82.69%, F1-Score: 82.70%\n",
            "Epoch 10/10 -> Loss: 0.2030, Accuracy sul Test Set: 82.77%, F1-Score: 82.77%\n",
            "Addestramento completato.\n",
            "\n",
            "--- Analisi: Merged Linear 15% (Only Head) ---\n",
            "Accuratezza Zero-Shot: 75.94%, F1-Score: 76.54%\n",
            "Strategia: Fine-tuning solo della testa (head).\n",
            "Inizio addestramento per 10 epoche...\n",
            "Epoch 1/10 -> Loss: 0.4748, Accuracy sul Test Set: 79.21%, F1-Score: 79.17%\n",
            "Epoch 2/10 -> Loss: 0.4698, Accuracy sul Test Set: 79.35%, F1-Score: 79.29%\n",
            "Epoch 3/10 -> Loss: 0.4687, Accuracy sul Test Set: 79.32%, F1-Score: 79.28%\n",
            "Epoch 4/10 -> Loss: 0.4671, Accuracy sul Test Set: 79.19%, F1-Score: 79.11%\n",
            "Epoch 5/10 -> Loss: 0.4677, Accuracy sul Test Set: 79.47%, F1-Score: 79.41%\n",
            "Epoch 6/10 -> Loss: 0.4670, Accuracy sul Test Set: 79.45%, F1-Score: 79.39%\n",
            "Epoch 7/10 -> Loss: 0.4631, Accuracy sul Test Set: 79.47%, F1-Score: 79.41%\n",
            "Epoch 8/10 -> Loss: 0.4642, Accuracy sul Test Set: 79.48%, F1-Score: 79.44%\n",
            "Epoch 9/10 -> Loss: 0.4641, Accuracy sul Test Set: 79.47%, F1-Score: 79.41%\n",
            "Epoch 10/10 -> Loss: 0.4631, Accuracy sul Test Set: 79.53%, F1-Score: 79.48%\n",
            "Addestramento completato.\n",
            "\n",
            "--- Analisi: Merged Linear 15% (Selective FT) ---\n",
            "Accuratezza Zero-Shot: 75.94%, F1-Score: 76.54%\n",
            "Strategia: Fine-tuning selettivo (layer non fusi + testa).\n",
            "Inizio addestramento per 10 epoche...\n",
            "Epoch 1/10 -> Loss: 0.4668, Accuracy sul Test Set: 79.73%, F1-Score: 79.68%\n",
            "Epoch 2/10 -> Loss: 0.4495, Accuracy sul Test Set: 80.03%, F1-Score: 79.96%\n",
            "Epoch 3/10 -> Loss: 0.4426, Accuracy sul Test Set: 80.41%, F1-Score: 80.35%\n",
            "Epoch 4/10 -> Loss: 0.4303, Accuracy sul Test Set: 80.52%, F1-Score: 80.44%\n",
            "Epoch 5/10 -> Loss: 0.4211, Accuracy sul Test Set: 80.62%, F1-Score: 80.56%\n",
            "Epoch 6/10 -> Loss: 0.4147, Accuracy sul Test Set: 80.84%, F1-Score: 80.78%\n",
            "Epoch 7/10 -> Loss: 0.4084, Accuracy sul Test Set: 80.92%, F1-Score: 80.87%\n",
            "Epoch 8/10 -> Loss: 0.4044, Accuracy sul Test Set: 81.13%, F1-Score: 81.09%\n",
            "Epoch 9/10 -> Loss: 0.4024, Accuracy sul Test Set: 81.03%, F1-Score: 80.97%\n",
            "Epoch 10/10 -> Loss: 0.3956, Accuracy sul Test Set: 81.20%, F1-Score: 81.15%\n",
            "Addestramento completato.\n",
            "\n",
            "--- Analisi: Merged Linear 15% (Full FT) ---\n",
            "Accuratezza Zero-Shot: 75.94%, F1-Score: 76.54%\n",
            "Strategia: Fine-tuning completo (nessun layer congelato).\n",
            "Inizio addestramento per 10 epoche...\n",
            "Epoch 1/10 -> Loss: 0.4231, Accuracy sul Test Set: 81.71%, F1-Score: 81.69%\n",
            "Epoch 2/10 -> Loss: 0.3661, Accuracy sul Test Set: 82.21%, F1-Score: 82.21%\n",
            "Epoch 3/10 -> Loss: 0.3341, Accuracy sul Test Set: 82.27%, F1-Score: 82.25%\n",
            "Epoch 4/10 -> Loss: 0.3091, Accuracy sul Test Set: 82.46%, F1-Score: 82.45%\n",
            "Epoch 5/10 -> Loss: 0.2870, Accuracy sul Test Set: 82.53%, F1-Score: 82.54%\n",
            "Epoch 6/10 -> Loss: 0.2696, Accuracy sul Test Set: 82.60%, F1-Score: 82.61%\n",
            "Epoch 7/10 -> Loss: 0.2501, Accuracy sul Test Set: 82.77%, F1-Score: 82.78%\n",
            "Epoch 8/10 -> Loss: 0.2322, Accuracy sul Test Set: 82.90%, F1-Score: 82.88%\n",
            "Epoch 9/10 -> Loss: 0.2136, Accuracy sul Test Set: 82.81%, F1-Score: 82.80%\n",
            "Epoch 10/10 -> Loss: 0.1974, Accuracy sul Test Set: 82.73%, F1-Score: 82.75%\n",
            "Addestramento completato.\n",
            "\n",
            "--- Analisi: Merged Avg Snr 15% (Only Head) ---\n",
            "Accuratezza Zero-Shot: 75.94%, F1-Score: 76.60%\n",
            "Strategia: Fine-tuning solo della testa (head).\n",
            "Inizio addestramento per 10 epoche...\n",
            "Epoch 1/10 -> Loss: 0.4715, Accuracy sul Test Set: 79.32%, F1-Score: 79.28%\n",
            "Epoch 2/10 -> Loss: 0.4692, Accuracy sul Test Set: 79.38%, F1-Score: 79.33%\n",
            "Epoch 3/10 -> Loss: 0.4692, Accuracy sul Test Set: 79.34%, F1-Score: 79.28%\n",
            "Epoch 4/10 -> Loss: 0.4688, Accuracy sul Test Set: 79.39%, F1-Score: 79.32%\n",
            "Epoch 5/10 -> Loss: 0.4657, Accuracy sul Test Set: 79.47%, F1-Score: 79.42%\n",
            "Epoch 6/10 -> Loss: 0.4647, Accuracy sul Test Set: 79.44%, F1-Score: 79.39%\n",
            "Epoch 7/10 -> Loss: 0.4658, Accuracy sul Test Set: 79.48%, F1-Score: 79.42%\n",
            "Epoch 8/10 -> Loss: 0.4625, Accuracy sul Test Set: 79.52%, F1-Score: 79.47%\n",
            "Epoch 9/10 -> Loss: 0.4630, Accuracy sul Test Set: 79.58%, F1-Score: 79.53%\n",
            "Epoch 10/10 -> Loss: 0.4623, Accuracy sul Test Set: 79.55%, F1-Score: 79.51%\n",
            "Addestramento completato.\n",
            "\n",
            "--- Analisi: Merged Avg Snr 15% (Selective FT) ---\n",
            "Accuratezza Zero-Shot: 75.94%, F1-Score: 76.60%\n",
            "Strategia: Fine-tuning selettivo (layer non fusi + testa).\n",
            "Inizio addestramento per 10 epoche...\n",
            "Epoch 1/10 -> Loss: 0.4621, Accuracy sul Test Set: 79.88%, F1-Score: 79.82%\n",
            "Epoch 2/10 -> Loss: 0.4470, Accuracy sul Test Set: 80.17%, F1-Score: 80.08%\n",
            "Epoch 3/10 -> Loss: 0.4360, Accuracy sul Test Set: 80.46%, F1-Score: 80.41%\n",
            "Epoch 4/10 -> Loss: 0.4276, Accuracy sul Test Set: 80.72%, F1-Score: 80.67%\n",
            "Epoch 5/10 -> Loss: 0.4177, Accuracy sul Test Set: 80.78%, F1-Score: 80.72%\n",
            "Epoch 6/10 -> Loss: 0.4134, Accuracy sul Test Set: 80.83%, F1-Score: 80.78%\n",
            "Epoch 7/10 -> Loss: 0.4097, Accuracy sul Test Set: 80.97%, F1-Score: 80.93%\n",
            "Epoch 8/10 -> Loss: 0.4019, Accuracy sul Test Set: 81.16%, F1-Score: 81.12%\n",
            "Epoch 9/10 -> Loss: 0.3976, Accuracy sul Test Set: 81.13%, F1-Score: 81.07%\n",
            "Epoch 10/10 -> Loss: 0.3950, Accuracy sul Test Set: 81.29%, F1-Score: 81.23%\n",
            "Addestramento completato.\n",
            "\n",
            "--- Analisi: Merged Avg Snr 15% (Full FT) ---\n",
            "Accuratezza Zero-Shot: 75.94%, F1-Score: 76.60%\n",
            "Strategia: Fine-tuning completo (nessun layer congelato).\n",
            "Inizio addestramento per 10 epoche...\n",
            "Epoch 1/10 -> Loss: 0.4230, Accuracy sul Test Set: 81.75%, F1-Score: 81.73%\n",
            "Epoch 2/10 -> Loss: 0.3666, Accuracy sul Test Set: 82.29%, F1-Score: 82.28%\n",
            "Epoch 3/10 -> Loss: 0.3360, Accuracy sul Test Set: 82.42%, F1-Score: 82.37%\n",
            "Epoch 4/10 -> Loss: 0.3089, Accuracy sul Test Set: 82.58%, F1-Score: 82.57%\n",
            "Epoch 5/10 -> Loss: 0.2879, Accuracy sul Test Set: 82.56%, F1-Score: 82.56%\n",
            "Epoch 6/10 -> Loss: 0.2662, Accuracy sul Test Set: 82.72%, F1-Score: 82.71%\n",
            "Epoch 7/10 -> Loss: 0.2512, Accuracy sul Test Set: 82.84%, F1-Score: 82.85%\n",
            "Epoch 8/10 -> Loss: 0.2290, Accuracy sul Test Set: 82.83%, F1-Score: 82.82%\n",
            "Epoch 9/10 -> Loss: 0.2147, Accuracy sul Test Set: 82.81%, F1-Score: 82.80%\n",
            "Epoch 10/10 -> Loss: 0.1969, Accuracy sul Test Set: 82.76%, F1-Score: 82.78%\n",
            "Addestramento completato.\n",
            "\n",
            "--- Analisi: Merged Slerp 10% (Only Head) ---\n",
            "Accuratezza Zero-Shot: 75.41%, F1-Score: 76.20%\n",
            "Strategia: Fine-tuning solo della testa (head).\n",
            "Inizio addestramento per 10 epoche...\n",
            "Epoch 1/10 -> Loss: 0.4812, Accuracy sul Test Set: 79.07%, F1-Score: 78.99%\n",
            "Epoch 2/10 -> Loss: 0.4784, Accuracy sul Test Set: 79.13%, F1-Score: 79.07%\n",
            "Epoch 3/10 -> Loss: 0.4739, Accuracy sul Test Set: 79.28%, F1-Score: 79.22%\n",
            "Epoch 4/10 -> Loss: 0.4750, Accuracy sul Test Set: 79.21%, F1-Score: 79.13%\n",
            "Epoch 5/10 -> Loss: 0.4710, Accuracy sul Test Set: 79.44%, F1-Score: 79.39%\n",
            "Epoch 6/10 -> Loss: 0.4747, Accuracy sul Test Set: 79.39%, F1-Score: 79.31%\n",
            "Epoch 7/10 -> Loss: 0.4726, Accuracy sul Test Set: 79.41%, F1-Score: 79.37%\n",
            "Epoch 8/10 -> Loss: 0.4707, Accuracy sul Test Set: 79.32%, F1-Score: 79.27%\n",
            "Epoch 9/10 -> Loss: 0.4678, Accuracy sul Test Set: 79.46%, F1-Score: 79.41%\n",
            "Epoch 10/10 -> Loss: 0.4687, Accuracy sul Test Set: 79.51%, F1-Score: 79.47%\n",
            "Addestramento completato.\n",
            "\n",
            "--- Analisi: Merged Slerp 10% (Selective FT) ---\n",
            "Accuratezza Zero-Shot: 75.41%, F1-Score: 76.20%\n",
            "Strategia: Fine-tuning selettivo (layer non fusi + testa).\n",
            "Inizio addestramento per 10 epoche...\n",
            "Epoch 1/10 -> Loss: 0.4745, Accuracy sul Test Set: 79.67%, F1-Score: 79.61%\n",
            "Epoch 2/10 -> Loss: 0.4606, Accuracy sul Test Set: 79.89%, F1-Score: 79.81%\n",
            "Epoch 3/10 -> Loss: 0.4497, Accuracy sul Test Set: 80.16%, F1-Score: 80.09%\n",
            "Epoch 4/10 -> Loss: 0.4445, Accuracy sul Test Set: 80.25%, F1-Score: 80.17%\n",
            "Epoch 5/10 -> Loss: 0.4366, Accuracy sul Test Set: 80.41%, F1-Score: 80.34%\n",
            "Epoch 6/10 -> Loss: 0.4339, Accuracy sul Test Set: 80.58%, F1-Score: 80.49%\n",
            "Epoch 7/10 -> Loss: 0.4284, Accuracy sul Test Set: 80.57%, F1-Score: 80.51%\n",
            "Epoch 8/10 -> Loss: 0.4243, Accuracy sul Test Set: 80.79%, F1-Score: 80.74%\n",
            "Epoch 9/10 -> Loss: 0.4207, Accuracy sul Test Set: 80.80%, F1-Score: 80.74%\n",
            "Epoch 10/10 -> Loss: 0.4138, Accuracy sul Test Set: 80.84%, F1-Score: 80.77%\n",
            "Addestramento completato.\n",
            "\n",
            "--- Analisi: Merged Slerp 10% (Full FT) ---\n",
            "Accuratezza Zero-Shot: 75.41%, F1-Score: 76.20%\n",
            "Strategia: Fine-tuning completo (nessun layer congelato).\n",
            "Inizio addestramento per 10 epoche...\n",
            "Epoch 1/10 -> Loss: 0.4266, Accuracy sul Test Set: 81.81%, F1-Score: 81.79%\n",
            "Epoch 2/10 -> Loss: 0.3711, Accuracy sul Test Set: 82.31%, F1-Score: 82.31%\n",
            "Epoch 3/10 -> Loss: 0.3411, Accuracy sul Test Set: 82.37%, F1-Score: 82.36%\n",
            "Epoch 4/10 -> Loss: 0.3132, Accuracy sul Test Set: 82.58%, F1-Score: 82.59%\n",
            "Epoch 5/10 -> Loss: 0.2912, Accuracy sul Test Set: 82.47%, F1-Score: 82.46%\n",
            "Epoch 6/10 -> Loss: 0.2705, Accuracy sul Test Set: 82.63%, F1-Score: 82.66%\n",
            "Epoch 7/10 -> Loss: 0.2531, Accuracy sul Test Set: 82.88%, F1-Score: 82.89%\n",
            "Epoch 8/10 -> Loss: 0.2365, Accuracy sul Test Set: 82.90%, F1-Score: 82.87%\n",
            "Epoch 9/10 -> Loss: 0.2172, Accuracy sul Test Set: 82.72%, F1-Score: 82.74%\n",
            "Epoch 10/10 -> Loss: 0.2016, Accuracy sul Test Set: 82.80%, F1-Score: 82.78%\n",
            "Addestramento completato.\n",
            "\n",
            "--- Analisi: Merged Slerp 15% (Only Head) ---\n",
            "Accuratezza Zero-Shot: 75.91%, F1-Score: 76.51%\n",
            "Strategia: Fine-tuning solo della testa (head).\n",
            "Inizio addestramento per 10 epoche...\n",
            "Epoch 1/10 -> Loss: 0.4725, Accuracy sul Test Set: 79.12%, F1-Score: 79.08%\n",
            "Epoch 2/10 -> Loss: 0.4714, Accuracy sul Test Set: 79.31%, F1-Score: 79.25%\n",
            "Epoch 3/10 -> Loss: 0.4702, Accuracy sul Test Set: 79.36%, F1-Score: 79.31%\n",
            "Epoch 4/10 -> Loss: 0.4666, Accuracy sul Test Set: 79.41%, F1-Score: 79.37%\n",
            "Epoch 5/10 -> Loss: 0.4661, Accuracy sul Test Set: 79.43%, F1-Score: 79.38%\n",
            "Epoch 6/10 -> Loss: 0.4659, Accuracy sul Test Set: 79.41%, F1-Score: 79.36%\n",
            "Epoch 7/10 -> Loss: 0.4655, Accuracy sul Test Set: 79.49%, F1-Score: 79.43%\n",
            "Epoch 8/10 -> Loss: 0.4663, Accuracy sul Test Set: 79.43%, F1-Score: 79.38%\n",
            "Epoch 9/10 -> Loss: 0.4644, Accuracy sul Test Set: 79.51%, F1-Score: 79.46%\n",
            "Epoch 10/10 -> Loss: 0.4614, Accuracy sul Test Set: 79.53%, F1-Score: 79.48%\n",
            "Addestramento completato.\n",
            "\n",
            "--- Analisi: Merged Slerp 15% (Selective FT) ---\n",
            "Accuratezza Zero-Shot: 75.91%, F1-Score: 76.51%\n",
            "Strategia: Fine-tuning selettivo (layer non fusi + testa).\n",
            "Inizio addestramento per 10 epoche...\n",
            "Epoch 1/10 -> Loss: 0.4674, Accuracy sul Test Set: 79.75%, F1-Score: 79.68%\n",
            "Epoch 2/10 -> Loss: 0.4497, Accuracy sul Test Set: 80.10%, F1-Score: 80.01%\n",
            "Epoch 3/10 -> Loss: 0.4357, Accuracy sul Test Set: 80.34%, F1-Score: 80.27%\n",
            "Epoch 4/10 -> Loss: 0.4290, Accuracy sul Test Set: 80.57%, F1-Score: 80.50%\n",
            "Epoch 5/10 -> Loss: 0.4242, Accuracy sul Test Set: 80.65%, F1-Score: 80.57%\n",
            "Epoch 6/10 -> Loss: 0.4142, Accuracy sul Test Set: 80.82%, F1-Score: 80.78%\n",
            "Epoch 7/10 -> Loss: 0.4104, Accuracy sul Test Set: 81.00%, F1-Score: 80.91%\n",
            "Epoch 8/10 -> Loss: 0.4021, Accuracy sul Test Set: 81.05%, F1-Score: 80.98%\n",
            "Epoch 9/10 -> Loss: 0.3998, Accuracy sul Test Set: 81.16%, F1-Score: 81.10%\n",
            "Epoch 10/10 -> Loss: 0.3973, Accuracy sul Test Set: 81.27%, F1-Score: 81.20%\n",
            "Addestramento completato.\n",
            "\n",
            "--- Analisi: Merged Slerp 15% (Full FT) ---\n",
            "Accuratezza Zero-Shot: 75.91%, F1-Score: 76.51%\n",
            "Strategia: Fine-tuning completo (nessun layer congelato).\n",
            "Inizio addestramento per 10 epoche...\n",
            "Epoch 1/10 -> Loss: 0.4230, Accuracy sul Test Set: 81.62%, F1-Score: 81.60%\n",
            "Epoch 2/10 -> Loss: 0.3647, Accuracy sul Test Set: 82.20%, F1-Score: 82.18%\n",
            "Epoch 3/10 -> Loss: 0.3357, Accuracy sul Test Set: 82.35%, F1-Score: 82.35%\n",
            "Epoch 4/10 -> Loss: 0.3086, Accuracy sul Test Set: 82.54%, F1-Score: 82.51%\n",
            "Epoch 5/10 -> Loss: 0.2886, Accuracy sul Test Set: 82.48%, F1-Score: 82.48%\n",
            "Epoch 6/10 -> Loss: 0.2670, Accuracy sul Test Set: 82.63%, F1-Score: 82.61%\n",
            "Epoch 7/10 -> Loss: 0.2490, Accuracy sul Test Set: 82.68%, F1-Score: 82.67%\n",
            "Epoch 8/10 -> Loss: 0.2308, Accuracy sul Test Set: 82.74%, F1-Score: 82.75%\n",
            "Epoch 9/10 -> Loss: 0.2142, Accuracy sul Test Set: 82.74%, F1-Score: 82.72%\n",
            "Epoch 10/10 -> Loss: 0.1968, Accuracy sul Test Set: 82.75%, F1-Score: 82.80%\n",
            "Addestramento completato.\n",
            "\n",
            "--- Analisi: Merged Ties 10% (Only Head) ---\n",
            "Accuratezza Zero-Shot: 75.48%, F1-Score: 76.19%\n",
            "Strategia: Fine-tuning solo della testa (head).\n",
            "Inizio addestramento per 10 epoche...\n",
            "Epoch 1/10 -> Loss: 0.4804, Accuracy sul Test Set: 79.00%, F1-Score: 78.94%\n",
            "Epoch 2/10 -> Loss: 0.4779, Accuracy sul Test Set: 79.06%, F1-Score: 78.98%\n",
            "Epoch 3/10 -> Loss: 0.4758, Accuracy sul Test Set: 79.16%, F1-Score: 79.10%\n",
            "Epoch 4/10 -> Loss: 0.4753, Accuracy sul Test Set: 79.20%, F1-Score: 79.13%\n",
            "Epoch 5/10 -> Loss: 0.4738, Accuracy sul Test Set: 79.30%, F1-Score: 79.25%\n",
            "Epoch 6/10 -> Loss: 0.4721, Accuracy sul Test Set: 79.35%, F1-Score: 79.29%\n",
            "Epoch 7/10 -> Loss: 0.4730, Accuracy sul Test Set: 79.34%, F1-Score: 79.26%\n",
            "Epoch 8/10 -> Loss: 0.4708, Accuracy sul Test Set: 79.43%, F1-Score: 79.36%\n",
            "Epoch 9/10 -> Loss: 0.4727, Accuracy sul Test Set: 79.36%, F1-Score: 79.30%\n",
            "Epoch 10/10 -> Loss: 0.4700, Accuracy sul Test Set: 79.30%, F1-Score: 79.24%\n",
            "Addestramento completato.\n",
            "\n",
            "--- Analisi: Merged Ties 10% (Selective FT) ---\n",
            "Accuratezza Zero-Shot: 75.48%, F1-Score: 76.19%\n",
            "Strategia: Fine-tuning selettivo (layer non fusi + testa).\n",
            "Inizio addestramento per 10 epoche...\n",
            "Epoch 1/10 -> Loss: 0.4787, Accuracy sul Test Set: 79.55%, F1-Score: 79.47%\n",
            "Epoch 2/10 -> Loss: 0.4596, Accuracy sul Test Set: 79.95%, F1-Score: 79.88%\n",
            "Epoch 3/10 -> Loss: 0.4541, Accuracy sul Test Set: 80.16%, F1-Score: 80.07%\n",
            "Epoch 4/10 -> Loss: 0.4470, Accuracy sul Test Set: 80.29%, F1-Score: 80.24%\n",
            "Epoch 5/10 -> Loss: 0.4418, Accuracy sul Test Set: 80.48%, F1-Score: 80.41%\n",
            "Epoch 6/10 -> Loss: 0.4328, Accuracy sul Test Set: 80.46%, F1-Score: 80.37%\n",
            "Epoch 7/10 -> Loss: 0.4301, Accuracy sul Test Set: 80.55%, F1-Score: 80.47%\n",
            "Epoch 8/10 -> Loss: 0.4237, Accuracy sul Test Set: 80.67%, F1-Score: 80.62%\n",
            "Epoch 9/10 -> Loss: 0.4211, Accuracy sul Test Set: 80.80%, F1-Score: 80.75%\n",
            "Epoch 10/10 -> Loss: 0.4186, Accuracy sul Test Set: 80.84%, F1-Score: 80.78%\n",
            "Addestramento completato.\n",
            "\n",
            "--- Analisi: Merged Ties 10% (Full FT) ---\n",
            "Accuratezza Zero-Shot: 75.48%, F1-Score: 76.19%\n",
            "Strategia: Fine-tuning completo (nessun layer congelato).\n",
            "Inizio addestramento per 10 epoche...\n",
            "Epoch 1/10 -> Loss: 0.4271, Accuracy sul Test Set: 81.79%, F1-Score: 81.79%\n",
            "Epoch 2/10 -> Loss: 0.3687, Accuracy sul Test Set: 82.30%, F1-Score: 82.27%\n",
            "Epoch 3/10 -> Loss: 0.3374, Accuracy sul Test Set: 82.35%, F1-Score: 82.36%\n",
            "Epoch 4/10 -> Loss: 0.3137, Accuracy sul Test Set: 82.42%, F1-Score: 82.41%\n",
            "Epoch 5/10 -> Loss: 0.2929, Accuracy sul Test Set: 82.49%, F1-Score: 82.49%\n",
            "Epoch 6/10 -> Loss: 0.2721, Accuracy sul Test Set: 82.63%, F1-Score: 82.61%\n",
            "Epoch 7/10 -> Loss: 0.2544, Accuracy sul Test Set: 82.62%, F1-Score: 82.61%\n",
            "Epoch 8/10 -> Loss: 0.2361, Accuracy sul Test Set: 82.65%, F1-Score: 82.67%\n",
            "Epoch 9/10 -> Loss: 0.2177, Accuracy sul Test Set: 82.64%, F1-Score: 82.66%\n",
            "Epoch 10/10 -> Loss: 0.2029, Accuracy sul Test Set: 82.71%, F1-Score: 82.71%\n",
            "Addestramento completato.\n",
            "\n",
            "--- Analisi: Merged Ties 15% (Only Head) ---\n",
            "Accuratezza Zero-Shot: 76.10%, F1-Score: 76.61%\n",
            "Strategia: Fine-tuning solo della testa (head).\n",
            "Inizio addestramento per 10 epoche...\n",
            "Epoch 1/10 -> Loss: 0.4741, Accuracy sul Test Set: 79.12%, F1-Score: 79.03%\n",
            "Epoch 2/10 -> Loss: 0.4726, Accuracy sul Test Set: 79.33%, F1-Score: 79.28%\n",
            "Epoch 3/10 -> Loss: 0.4722, Accuracy sul Test Set: 79.37%, F1-Score: 79.32%\n",
            "Epoch 4/10 -> Loss: 0.4680, Accuracy sul Test Set: 79.33%, F1-Score: 79.27%\n",
            "Epoch 5/10 -> Loss: 0.4690, Accuracy sul Test Set: 79.45%, F1-Score: 79.38%\n",
            "Epoch 6/10 -> Loss: 0.4685, Accuracy sul Test Set: 79.49%, F1-Score: 79.43%\n",
            "Epoch 7/10 -> Loss: 0.4664, Accuracy sul Test Set: 79.43%, F1-Score: 79.37%\n",
            "Epoch 8/10 -> Loss: 0.4680, Accuracy sul Test Set: 79.50%, F1-Score: 79.43%\n",
            "Epoch 9/10 -> Loss: 0.4674, Accuracy sul Test Set: 79.44%, F1-Score: 79.38%\n",
            "Epoch 10/10 -> Loss: 0.4654, Accuracy sul Test Set: 79.55%, F1-Score: 79.49%\n",
            "Addestramento completato.\n",
            "\n",
            "--- Analisi: Merged Ties 15% (Selective FT) ---\n",
            "Accuratezza Zero-Shot: 76.10%, F1-Score: 76.61%\n",
            "Strategia: Fine-tuning selettivo (layer non fusi + testa).\n",
            "Inizio addestramento per 10 epoche...\n",
            "Epoch 1/10 -> Loss: 0.4640, Accuracy sul Test Set: 79.78%, F1-Score: 79.72%\n",
            "Epoch 2/10 -> Loss: 0.4490, Accuracy sul Test Set: 80.08%, F1-Score: 79.99%\n",
            "Epoch 3/10 -> Loss: 0.4393, Accuracy sul Test Set: 80.34%, F1-Score: 80.29%\n",
            "Epoch 4/10 -> Loss: 0.4286, Accuracy sul Test Set: 80.76%, F1-Score: 80.69%\n",
            "Epoch 5/10 -> Loss: 0.4232, Accuracy sul Test Set: 80.66%, F1-Score: 80.60%\n",
            "Epoch 6/10 -> Loss: 0.4162, Accuracy sul Test Set: 80.75%, F1-Score: 80.68%\n",
            "Epoch 7/10 -> Loss: 0.4090, Accuracy sul Test Set: 81.01%, F1-Score: 80.95%\n",
            "Epoch 8/10 -> Loss: 0.4061, Accuracy sul Test Set: 81.12%, F1-Score: 81.06%\n",
            "Epoch 9/10 -> Loss: 0.4040, Accuracy sul Test Set: 81.19%, F1-Score: 81.14%\n",
            "Epoch 10/10 -> Loss: 0.3967, Accuracy sul Test Set: 81.26%, F1-Score: 81.22%\n",
            "Addestramento completato.\n",
            "\n",
            "--- Analisi: Merged Ties 15% (Full FT) ---\n",
            "Accuratezza Zero-Shot: 76.10%, F1-Score: 76.61%\n",
            "Strategia: Fine-tuning completo (nessun layer congelato).\n",
            "Inizio addestramento per 10 epoche...\n",
            "Epoch 1/10 -> Loss: 0.4222, Accuracy sul Test Set: 81.70%, F1-Score: 81.73%\n",
            "Epoch 2/10 -> Loss: 0.3680, Accuracy sul Test Set: 82.16%, F1-Score: 82.14%\n",
            "Epoch 3/10 -> Loss: 0.3377, Accuracy sul Test Set: 82.35%, F1-Score: 82.33%\n",
            "Epoch 4/10 -> Loss: 0.3140, Accuracy sul Test Set: 82.52%, F1-Score: 82.52%\n",
            "Epoch 5/10 -> Loss: 0.2903, Accuracy sul Test Set: 82.49%, F1-Score: 82.46%\n",
            "Epoch 6/10 -> Loss: 0.2708, Accuracy sul Test Set: 82.69%, F1-Score: 82.71%\n",
            "Epoch 7/10 -> Loss: 0.2500, Accuracy sul Test Set: 82.78%, F1-Score: 82.77%\n",
            "Epoch 8/10 -> Loss: 0.2317, Accuracy sul Test Set: 82.75%, F1-Score: 82.78%\n",
            "Epoch 9/10 -> Loss: 0.2169, Accuracy sul Test Set: 82.91%, F1-Score: 82.91%\n",
            "Epoch 10/10 -> Loss: 0.1996, Accuracy sul Test Set: 82.87%, F1-Score: 82.89%\n",
            "Addestramento completato.\n",
            "\n",
            "--- Analisi: Full LERP (Only Head) ---\n",
            "Accuratezza Zero-Shot: 17.72%, F1-Score: 14.47%\n",
            "Strategia: Fine-tuning solo della testa (head).\n",
            "Inizio addestramento per 10 epoche...\n",
            "Epoch 1/10 -> Loss: 2.3751, Accuracy sul Test Set: 40.30%, F1-Score: 38.88%\n",
            "Epoch 2/10 -> Loss: 2.2795, Accuracy sul Test Set: 40.94%, F1-Score: 39.47%\n",
            "Epoch 3/10 -> Loss: 2.1914, Accuracy sul Test Set: 41.63%, F1-Score: 40.17%\n",
            "Epoch 4/10 -> Loss: 2.1059, Accuracy sul Test Set: 42.38%, F1-Score: 40.94%\n",
            "Epoch 5/10 -> Loss: 2.0339, Accuracy sul Test Set: 43.12%, F1-Score: 41.62%\n",
            "Epoch 6/10 -> Loss: 1.9556, Accuracy sul Test Set: 44.12%, F1-Score: 42.46%\n",
            "Epoch 7/10 -> Loss: 1.8751, Accuracy sul Test Set: 45.19%, F1-Score: 43.41%\n",
            "Epoch 8/10 -> Loss: 1.8153, Accuracy sul Test Set: 45.88%, F1-Score: 44.01%\n",
            "Epoch 9/10 -> Loss: 1.7420, Accuracy sul Test Set: 46.94%, F1-Score: 45.00%\n",
            "Epoch 10/10 -> Loss: 1.6842, Accuracy sul Test Set: 47.80%, F1-Score: 45.62%\n",
            "Addestramento completato.\n",
            "\n",
            "--- Analisi: Full LERP (Selective FT) ---\n",
            "Accuratezza Zero-Shot: 17.72%, F1-Score: 14.47%\n",
            "Strategia: Fine-tuning selettivo (layer non fusi + testa).\n",
            "Inizio addestramento per 10 epoche...\n",
            "Epoch 1/10 -> Loss: 1.1519, Accuracy sul Test Set: 75.53%, F1-Score: 74.83%\n",
            "Epoch 2/10 -> Loss: 0.4729, Accuracy sul Test Set: 79.51%, F1-Score: 79.28%\n",
            "Epoch 3/10 -> Loss: 0.3538, Accuracy sul Test Set: 80.70%, F1-Score: 80.59%\n",
            "Epoch 4/10 -> Loss: 0.2973, Accuracy sul Test Set: 81.62%, F1-Score: 81.54%\n",
            "Epoch 5/10 -> Loss: 0.2601, Accuracy sul Test Set: 81.93%, F1-Score: 81.86%\n",
            "Epoch 6/10 -> Loss: 0.2300, Accuracy sul Test Set: 82.00%, F1-Score: 81.94%\n",
            "Epoch 7/10 -> Loss: 0.2055, Accuracy sul Test Set: 82.31%, F1-Score: 82.29%\n",
            "Epoch 8/10 -> Loss: 0.1868, Accuracy sul Test Set: 82.33%, F1-Score: 82.32%\n",
            "Epoch 9/10 -> Loss: 0.1699, Accuracy sul Test Set: 82.27%, F1-Score: 82.27%\n",
            "Epoch 10/10 -> Loss: 0.1524, Accuracy sul Test Set: 82.37%, F1-Score: 82.37%\n",
            "Addestramento completato.\n",
            "\n",
            "--- SALTO: Full LERP (Full FT) perché ridondante con Selective FT ---\n",
            "\n",
            "--- Analisi: Full SLERP (Only Head) ---\n",
            "Accuratezza Zero-Shot: 20.06%, F1-Score: 17.58%\n",
            "Strategia: Fine-tuning solo della testa (head).\n",
            "Inizio addestramento per 10 epoche...\n",
            "Epoch 1/10 -> Loss: 2.3866, Accuracy sul Test Set: 40.40%, F1-Score: 38.95%\n",
            "Epoch 2/10 -> Loss: 2.2837, Accuracy sul Test Set: 40.77%, F1-Score: 39.30%\n",
            "Epoch 3/10 -> Loss: 2.1994, Accuracy sul Test Set: 41.66%, F1-Score: 40.18%\n",
            "Epoch 4/10 -> Loss: 2.1139, Accuracy sul Test Set: 42.27%, F1-Score: 40.83%\n",
            "Epoch 5/10 -> Loss: 2.0360, Accuracy sul Test Set: 42.83%, F1-Score: 41.29%\n",
            "Epoch 6/10 -> Loss: 1.9580, Accuracy sul Test Set: 43.80%, F1-Score: 42.25%\n",
            "Epoch 7/10 -> Loss: 1.8808, Accuracy sul Test Set: 45.03%, F1-Score: 43.26%\n",
            "Epoch 8/10 -> Loss: 1.8152, Accuracy sul Test Set: 45.90%, F1-Score: 44.12%\n",
            "Epoch 9/10 -> Loss: 1.7440, Accuracy sul Test Set: 46.91%, F1-Score: 44.89%\n",
            "Epoch 10/10 -> Loss: 1.6864, Accuracy sul Test Set: 47.74%, F1-Score: 45.56%\n",
            "Addestramento completato.\n",
            "\n",
            "--- Analisi: Full SLERP (Selective FT) ---\n",
            "Accuratezza Zero-Shot: 20.06%, F1-Score: 17.58%\n",
            "Strategia: Fine-tuning selettivo (layer non fusi + testa).\n",
            "Inizio addestramento per 10 epoche...\n",
            "Epoch 1/10 -> Loss: 1.1743, Accuracy sul Test Set: 75.23%, F1-Score: 74.54%\n",
            "Epoch 2/10 -> Loss: 0.4809, Accuracy sul Test Set: 79.33%, F1-Score: 79.09%\n",
            "Epoch 3/10 -> Loss: 0.3602, Accuracy sul Test Set: 80.87%, F1-Score: 80.74%\n",
            "Epoch 4/10 -> Loss: 0.3014, Accuracy sul Test Set: 81.51%, F1-Score: 81.42%\n",
            "Epoch 5/10 -> Loss: 0.2624, Accuracy sul Test Set: 82.04%, F1-Score: 81.97%\n",
            "Epoch 6/10 -> Loss: 0.2339, Accuracy sul Test Set: 82.16%, F1-Score: 82.12%\n",
            "Epoch 7/10 -> Loss: 0.2087, Accuracy sul Test Set: 82.29%, F1-Score: 82.27%\n",
            "Epoch 8/10 -> Loss: 0.1905, Accuracy sul Test Set: 82.32%, F1-Score: 82.29%\n",
            "Epoch 9/10 -> Loss: 0.1728, Accuracy sul Test Set: 82.27%, F1-Score: 82.25%\n",
            "Epoch 10/10 -> Loss: 0.1565, Accuracy sul Test Set: 82.35%, F1-Score: 82.32%\n",
            "Addestramento completato.\n",
            "\n",
            "--- SALTO: Full SLERP (Full FT) perché ridondante con Selective FT ---\n",
            "\n",
            "--- Analisi: Full TIES (Only Head) ---\n",
            "Accuratezza Zero-Shot: 32.54%, F1-Score: 32.84%\n",
            "Strategia: Fine-tuning solo della testa (head).\n",
            "Inizio addestramento per 10 epoche...\n",
            "Epoch 1/10 -> Loss: 1.9946, Accuracy sul Test Set: 46.73%, F1-Score: 45.24%\n",
            "Epoch 2/10 -> Loss: 1.9162, Accuracy sul Test Set: 47.32%, F1-Score: 45.80%\n",
            "Epoch 3/10 -> Loss: 1.8469, Accuracy sul Test Set: 48.14%, F1-Score: 46.68%\n",
            "Epoch 4/10 -> Loss: 1.7744, Accuracy sul Test Set: 48.90%, F1-Score: 47.45%\n",
            "Epoch 5/10 -> Loss: 1.7077, Accuracy sul Test Set: 49.89%, F1-Score: 48.28%\n",
            "Epoch 6/10 -> Loss: 1.6500, Accuracy sul Test Set: 50.80%, F1-Score: 49.12%\n",
            "Epoch 7/10 -> Loss: 1.5842, Accuracy sul Test Set: 51.61%, F1-Score: 49.78%\n",
            "Epoch 8/10 -> Loss: 1.5320, Accuracy sul Test Set: 52.12%, F1-Score: 50.19%\n",
            "Epoch 9/10 -> Loss: 1.4828, Accuracy sul Test Set: 53.20%, F1-Score: 51.10%\n",
            "Epoch 10/10 -> Loss: 1.4234, Accuracy sul Test Set: 53.90%, F1-Score: 51.66%\n",
            "Addestramento completato.\n",
            "\n",
            "--- Analisi: Full TIES (Selective FT) ---\n",
            "Accuratezza Zero-Shot: 32.54%, F1-Score: 32.84%\n",
            "Strategia: Fine-tuning selettivo (layer non fusi + testa).\n",
            "Inizio addestramento per 10 epoche...\n",
            "Epoch 1/10 -> Loss: 0.9398, Accuracy sul Test Set: 78.34%, F1-Score: 77.88%\n",
            "Epoch 2/10 -> Loss: 0.4152, Accuracy sul Test Set: 80.67%, F1-Score: 80.48%\n",
            "Epoch 3/10 -> Loss: 0.3322, Accuracy sul Test Set: 81.70%, F1-Score: 81.61%\n",
            "Epoch 4/10 -> Loss: 0.2889, Accuracy sul Test Set: 82.10%, F1-Score: 82.03%\n",
            "Epoch 5/10 -> Loss: 0.2588, Accuracy sul Test Set: 82.42%, F1-Score: 82.38%\n",
            "Epoch 6/10 -> Loss: 0.2324, Accuracy sul Test Set: 82.45%, F1-Score: 82.40%\n",
            "Epoch 7/10 -> Loss: 0.2141, Accuracy sul Test Set: 82.26%, F1-Score: 82.23%\n",
            "Epoch 8/10 -> Loss: 0.1922, Accuracy sul Test Set: 82.43%, F1-Score: 82.40%\n",
            "Epoch 9/10 -> Loss: 0.1758, Accuracy sul Test Set: 82.50%, F1-Score: 82.48%\n",
            "Epoch 10/10 -> Loss: 0.1588, Accuracy sul Test Set: 82.33%, F1-Score: 82.32%\n",
            "Addestramento completato.\n",
            "\n",
            "--- SALTO: Full TIES (Full FT) perché ridondante con Selective FT ---\n"
          ]
        }
      ],
      "source": [
        "from src.test import finetuning_experiments\n",
        "results = finetuning_experiments(model, model_A, model_B, merged_models_to_evaluate, loader_full_train, loader_full_test, device, is_alignment_noop)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B2O_SKssLpar",
        "outputId": "319582a3-1b8a-462d-d675-3749eda9843f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "======================================================================================================================================================\n",
            "======== RIEPILOGO COMPLETO DELL'ESPERIMENTO ========\n",
            "======================================================================================================================================================\n",
            "Modello / Strategia                                     | Acc. Zero-Shot (%)     | Acc. Fine-Tuned (%)    | F1 Fine-Tuned (%)      | Tempo Add. (s)     | Picco RAM (GB)    \n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Base Model + Fine-Tune                                  | 73.75                  | 82.76                  | 82.75                  | 104.30             | 13.19             \n",
            "Merged Linear 10% (Only Head)                           | 75.39                  | 79.32                  | 79.23                  | 45.25              | 1.39              \n",
            "Merged Linear 10% (Selective FT)                        | 75.39                  | 80.87                  | 80.82                  | 60.83              | 4.66              \n",
            "Merged Linear 10% (Full FT)                             | 75.39                  | 82.77                  | 82.77                  | 104.28             | 13.20             \n",
            "Merged Linear 15% (Only Head)                           | 75.94                  | 79.53                  | 79.48                  | 45.24              | 1.39              \n",
            "Merged Linear 15% (Selective FT)                        | 75.94                  | 81.20                  | 81.15                  | 85.66              | 11.85             \n",
            "Merged Linear 15% (Full FT)                             | 75.94                  | 82.73                  | 82.75                  | 104.31             | 13.20             \n",
            "Merged Avg Snr 15% (Only Head)                          | 75.94                  | 79.55                  | 79.51                  | 45.25              | 1.39              \n",
            "Merged Avg Snr 15% (Selective FT)                       | 75.94                  | 81.29                  | 81.23                  | 85.18              | 11.85             \n",
            "Merged Avg Snr 15% (Full FT)                            | 75.94                  | 82.76                  | 82.78                  | 104.34             | 13.20             \n",
            "Merged Slerp 10% (Only Head)                            | 75.41                  | 79.51                  | 79.47                  | 45.30              | 1.39              \n",
            "Merged Slerp 10% (Selective FT)                         | 75.41                  | 80.84                  | 80.77                  | 60.92              | 4.66              \n",
            "Merged Slerp 10% (Full FT)                              | 75.41                  | 82.80                  | 82.78                  | 104.29             | 13.20             \n",
            "Merged Slerp 15% (Only Head)                            | 75.91                  | 79.53                  | 79.48                  | 45.27              | 1.39              \n",
            "Merged Slerp 15% (Selective FT)                         | 75.91                  | 81.27                  | 81.20                  | 85.70              | 11.85             \n",
            "Merged Slerp 15% (Full FT)                              | 75.91                  | 82.75                  | 82.80                  | 104.37             | 13.20             \n",
            "Merged Ties 10% (Only Head)                             | 75.48                  | 79.30                  | 79.24                  | 45.27              | 1.39              \n",
            "Merged Ties 10% (Selective FT)                          | 75.48                  | 80.84                  | 80.78                  | 60.84              | 4.66              \n",
            "Merged Ties 10% (Full FT)                               | 75.48                  | 82.71                  | 82.71                  | 104.34             | 13.20             \n",
            "Merged Ties 15% (Only Head)                             | 76.10                  | 79.55                  | 79.49                  | 45.25              | 1.39              \n",
            "Merged Ties 15% (Selective FT)                          | 76.10                  | 81.26                  | 81.22                  | 85.71              | 11.85             \n",
            "Merged Ties 15% (Full FT)                               | 76.10                  | 82.87                  | 82.89                  | 105.62             | 13.20             \n",
            "Full LERP (Only Head)                                   | 17.72                  | 47.80                  | 45.62                  | 45.51              | 1.39              \n",
            "Full LERP (Selective FT)                                | 17.72                  | 82.37                  | 82.37                  | 104.59             | 13.20             \n",
            "Full SLERP (Only Head)                                  | 20.06                  | 47.74                  | 45.56                  | 45.30              | 1.39              \n",
            "Full SLERP (Selective FT)                               | 20.06                  | 82.35                  | 82.32                  | 104.35             | 13.20             \n",
            "Full TIES (Only Head)                                   | 32.54                  | 53.90                  | 51.66                  | 45.31              | 1.39              \n",
            "Full TIES (Selective FT)                                | 32.54                  | 82.33                  | 82.32                  | 104.43             | 13.20             \n",
            "======================================================================================================================================================\n"
          ]
        }
      ],
      "source": [
        "#Intestazione della tabella\n",
        "header = (\n",
        "    f\"{'Modello (Strategia)':<55} | \"\n",
        "    f\"{'Acc. Zero-Shot (%)':<22} | \"\n",
        "    f\"{'Acc. Fine-Tuned (%)':<22} | \"\n",
        "    f\"{'F1 Fine-Tuned (%)':<22} | \"\n",
        "    f\"{'Tempo Add. (s)':<18} | \"\n",
        "    f\"{'Picco RAM (GB)':<18}\"\n",
        ")\n",
        "print(header)\n",
        "print(\"-\"*150)\n",
        "\n",
        "\n",
        "for name, res_data in results.items():\n",
        "    acc_zs = res_data.get('acc_zero_shot')\n",
        "    acc_ft = res_data.get('acc_finetuned')\n",
        "    f1_ft = res_data.get('f1_finetuned')\n",
        "    t = res_data.get('time')\n",
        "    mem = res_data.get('ram_gb')\n",
        "\n",
        "    #(\"N/A\" se un dato non è applicabile)\n",
        "    acc_zs_str = f\"{acc_zs:.2f}\" if acc_zs is not None else \"N/A\"\n",
        "    acc_ft_str = f\"{acc_ft:.2f}\" if acc_ft is not None else \"N/A\"\n",
        "    f1_ft_str = f\"{f1_ft:.2f}\" if f1_ft is not None else \"N/A\"\n",
        "    t_str = f\"{t:.2f}\" if t is not None else \"N/A\"\n",
        "    mem_str = f\"{mem:.2f}\" if mem is not None else \"N/A\"\n",
        "\n",
        "    print(\n",
        "        f\"{name:<55} | \"\n",
        "        f\"{acc_zs_str:<22} | \"\n",
        "        f\"{acc_ft_str:<22} | \"\n",
        "        f\"{f1_ft_str:<22} | \"\n",
        "        f\"{t_str:<18} | \"\n",
        "        f\"{mem_str:<18}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylsMJGvW5bcB"
      },
      "source": [
        "## Plot finali"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oi-dBhyy-Mhc"
      },
      "outputs": [],
      "source": [
        "from src.utils import get_plot_colors, get_group_name, extract_metrics_from_results\n",
        "\n",
        "metrics = extract_metrics_from_results(results, \"Base Model + Fine-Tune\")\n",
        "\n",
        "labels_acc, data_acc, baseline_acc, min_baseline_acc = metrics[\"acc\"]\n",
        "labels_f1, data_f1, baseline_f1, min_baseline_f1 = metrics[\"f1\"]\n",
        "labels_time, data_time, baseline_time = metrics[\"time\"]\n",
        "labels_mem, data_mem, baseline_mem = metrics[\"mem\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Grafico 1: Accuratezza Fine-Tuned"
      ],
      "metadata": {
        "id": "D-JHq1X162LW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if data_acc:\n",
        "    plt.figure(figsize=(18, 6))\n",
        "\n",
        "\n",
        "    zipped_data = sorted(zip(labels_acc, data_acc), key=lambda x: get_group_name(x[0]))\n",
        "    sorted_labels = [item[0] for item in zipped_data]\n",
        "    sorted_data = [item[1] for item in zipped_data]\n",
        "\n",
        "    bar_width = 0.9\n",
        "    group_gap = 0.5\n",
        "    x_positions = []\n",
        "    current_x = 0\n",
        "    for i, name in enumerate(sorted_labels):\n",
        "        if i > 0 and get_group_name(name) != get_group_name(sorted_labels[i-1]):\n",
        "            current_x += group_gap\n",
        "        x_positions.append(current_x)\n",
        "        current_x += bar_width\n",
        "\n",
        "\n",
        "    colors = get_plot_colors(sorted_labels)\n",
        "    bars = plt.bar(x_positions, sorted_data, color=colors, width=bar_width)\n",
        "\n",
        "    if baseline_acc is not None:\n",
        "        plt.axhline(y=baseline_acc, color='r', linestyle='--', linewidth=1, label=f'Baseline (Base Model FT): {baseline_acc:.2f}%')\n",
        "        plt.legend()\n",
        "    if min_baseline_acc is not None and min_baseline_acc != baseline_acc:\n",
        "        plt.axhline(y=min_baseline_acc, color='blue', linestyle='--', linewidth=1, label=f'Min Baseline (Base Model): {min_baseline_acc:.2f}%')\n",
        "        plt.legend()\n",
        "    plt.ylabel('Accuratezza (%)', fontsize=12)\n",
        "    plt.title('Confronto Accuratezza Post-Fine-Tuning (Modelli Raggruppati)', fontsize=16)\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    plt.ylim(0, max(sorted_data) * 1.15)\n",
        "\n",
        "\n",
        "    plt.xticks(ticks=x_positions, labels=sorted_labels, rotation=45, ha=\"right\")\n",
        "\n",
        "    for i, bar in enumerate(bars):\n",
        "        yval = bar.get_height()\n",
        "        plt.text(x_positions[i], yval + 1, f'{yval:.2f}%', ha='center', va='bottom')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "-PHfDriH6zA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Grafico 2: F1-Score Fine-Tuned"
      ],
      "metadata": {
        "id": "h9c3_yqb6sqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if data_f1:\n",
        "    plt.figure(figsize=(18, 6))\n",
        "\n",
        "    zipped_data = sorted(zip(labels_f1, data_f1), key=lambda x: get_group_name(x[0]))\n",
        "    sorted_labels = [item[0] for item in zipped_data]\n",
        "    sorted_data = [item[1] for item in zipped_data]\n",
        "\n",
        "    bar_width = 0.9\n",
        "    group_gap = 0.5\n",
        "    x_positions = []\n",
        "    current_x = 0\n",
        "    for i, name in enumerate(sorted_labels):\n",
        "        if i > 0 and get_group_name(name) != get_group_name(sorted_labels[i-1]):\n",
        "            current_x += group_gap\n",
        "        x_positions.append(current_x)\n",
        "        current_x += bar_width\n",
        "\n",
        "    colors = get_plot_colors(sorted_labels)\n",
        "    bars = plt.bar(x_positions, sorted_data, color=colors, width=bar_width)\n",
        "\n",
        "    if baseline_f1 is not None:\n",
        "        plt.axhline(y=baseline_f1, color='r', linestyle='--', linewidth=1, label=f'Baseline (Base Model FT): {baseline_f1:.2f}%')\n",
        "        plt.legend()\n",
        "    if min_baseline_f1 is not None and min_baseline_f1 != baseline_f1:\n",
        "        plt.axhline(y=min_baseline_f1, color='blue', linestyle='--', linewidth=1, label=f'Min Baseline (Base Model FT): {min_baseline_f1:.2f}%')\n",
        "        plt.legend()\n",
        "\n",
        "    plt.ylabel('F1-Score (%)', fontsize=12)\n",
        "    plt.title('Confronto F1-Score Post-Fine-Tuning (Modelli Raggruppati)', fontsize=16)\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    plt.ylim(0, max(sorted_data) * 1.15)\n",
        "\n",
        "    plt.xticks(ticks=x_positions, labels=sorted_labels, rotation=45, ha=\"right\")\n",
        "\n",
        "    for bar in bars:\n",
        "        yval = bar.get_height()\n",
        "        center_x = bar.get_x() + bar.get_width() / 2.0  # Calcola il centro della barra\n",
        "        plt.text(center_x, yval, f'{yval:.2f}%', ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "r7kVUp1e6qLc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Grafico 3: Tempo di Addestramento"
      ],
      "metadata": {
        "id": "Q3IFuUAI6hVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if data_time:\n",
        "    plt.figure(figsize=(15, 6))\n",
        "\n",
        "    zipped_data = sorted(zip(labels_time, data_time), key=lambda x: get_group_name(x[0]))\n",
        "    sorted_labels = [item[0] for item in zipped_data]\n",
        "    sorted_data = [item[1] for item in zipped_data]\n",
        "\n",
        "    bar_width = 0.9\n",
        "    group_gap = 0.5\n",
        "    x_positions = []\n",
        "    current_x = 0\n",
        "    for i, name in enumerate(sorted_labels):\n",
        "        if i > 0 and get_group_name(name) != get_group_name(sorted_labels[i-1]):\n",
        "            current_x += group_gap\n",
        "        x_positions.append(current_x)\n",
        "        current_x += bar_width\n",
        "\n",
        "    colors = get_plot_colors(sorted_labels)\n",
        "    bars = plt.bar(x_positions, sorted_data, color=colors, width=bar_width)\n",
        "\n",
        "    if baseline_time is not None:\n",
        "        plt.axhline(y=baseline_time, color='r', linestyle='--', linewidth=1, label=f'Baseline (Base Model FT): {baseline_time:.2f}s')\n",
        "        plt.legend()\n",
        "\n",
        "    plt.ylabel('Tempo (secondi)', fontsize=12)\n",
        "    plt.title('Confronto Tempo di Addestramento (Modelli Raggruppati)', fontsize=16)\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    plt.ylim(0, max(sorted_data) * 1.15)\n",
        "    plt.xticks(ticks=x_positions, labels=sorted_labels, rotation=45, ha=\"right\")\n",
        "\n",
        "    for i, bar in enumerate(bars):\n",
        "        yval = bar.get_height()\n",
        "        plt.text(x_positions[i], yval + 0.5, f'{yval:.2f}s', ha='center', va='bottom')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "1sAjgIOt6edl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Grafico 4: Picco di Utilizzo Memoria"
      ],
      "metadata": {
        "id": "4y4mxo1a5ipu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if data_mem:\n",
        "    plt.figure(figsize=(18, 6))\n",
        "\n",
        "    zipped_data = sorted(zip(labels_mem, data_mem), key=lambda x: get_group_name(x[0]))\n",
        "    sorted_labels = [item[0] for item in zipped_data]\n",
        "    sorted_data = [item[1] for item in zipped_data]\n",
        "\n",
        "    bar_width = 0.9\n",
        "    group_gap = 0.5\n",
        "    x_positions = []\n",
        "    current_x = 0\n",
        "    for i, name in enumerate(sorted_labels):\n",
        "        if i > 0 and get_group_name(name) != get_group_name(sorted_labels[i-1]):\n",
        "            current_x += group_gap\n",
        "        x_positions.append(current_x)\n",
        "        current_x += bar_width\n",
        "\n",
        "    colors = get_plot_colors(sorted_labels)\n",
        "    bars = plt.bar(x_positions, sorted_data, color=colors, width=bar_width)\n",
        "\n",
        "    if baseline_mem is not None:\n",
        "        plt.axhline(y=baseline_mem, color='r', linestyle='--', linewidth=1, label=f'Baseline (Base Model FT): {baseline_mem:.2f}GB')\n",
        "        plt.legend()\n",
        "\n",
        "    plt.ylabel('Picco Memoria (GB)', fontsize=12)\n",
        "    plt.title('Confronto Picco di Utilizzo Memoria (Modelli Raggruppati)', fontsize=16)\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    plt.ylim(0, max(sorted_data) * 1.20)\n",
        "    plt.xticks(ticks=x_positions, labels=sorted_labels, rotation=45, ha=\"right\")\n",
        "\n",
        "    for i, bar in enumerate(bars):\n",
        "        yval = bar.get_height()\n",
        "        plt.text(x_positions[i], yval, f'{yval:.2f}GB', ha='center', va='bottom', rotation=0, fontsize=9)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "ZwbX5NHJ5h4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if baseline_acc is not None and baseline_time is not None and baseline_mem is not None:\n",
        "\n",
        "    efficiency_labels = []\n",
        "    acc_change_data = []\n",
        "    f1_change_data = []\n",
        "    time_gain_data = []\n",
        "    mem_gain_data = []\n",
        "\n",
        "    #Preparazione dei dati: dizionario temporaneo per ordinare prima per gruppo o poi per nome\n",
        "    temp_results = {k: v for k, v in results.items() if k != baseline_model_name}\n",
        "    sorted_items = sorted(temp_results.items(), key=lambda item: (get_group_name(item[0]), item[0]))\n",
        "\n",
        "    for name, res in sorted_items:\n",
        "        efficiency_labels.append(name)\n",
        "\n",
        "        acc_change = ((res.get('acc_finetuned', baseline_acc) - baseline_acc) / baseline_acc) * 100\n",
        "        f1_change = ((res.get('f1_finetuned', baseline_f1) - baseline_f1) / baseline_f1) * 100\n",
        "        acc_change_data.append(acc_change)\n",
        "        f1_change_data.append(f1_change)\n",
        "\n",
        "        time_gain = ((baseline_time - res.get('time', baseline_time)) / baseline_time) * 100\n",
        "        mem_gain = ((baseline_mem - res.get('ram_gb', baseline_mem)) / baseline_mem) * 100\n",
        "        time_gain_data.append(time_gain)\n",
        "        mem_gain_data.append(mem_gain)\n",
        "\n",
        "    bar_width = 0.9\n",
        "    group_gap = 0.5\n",
        "    x_positions = []\n",
        "    current_x = 0\n",
        "    for i, name in enumerate(efficiency_labels):\n",
        "        if i > 0 and get_group_name(name) != get_group_name(efficiency_labels[i-1]):\n",
        "            current_x += group_gap\n",
        "        x_positions.append(current_x)\n",
        "        current_x += bar_width\n",
        "\n",
        "    colors = get_plot_colors(efficiency_labels)\n",
        "\n",
        "    #Plot 1: Variazione Accuratezza\n",
        "    plt.figure(figsize=(15, 6))\n",
        "    bars = plt.bar(x_positions, acc_change_data, color=colors, width=bar_width)\n",
        "    plt.axhline(y=0, color='black', linestyle='-', linewidth=1)\n",
        "    plt.ylabel('Variazione Accuratezza (%) vs Baseline')\n",
        "    plt.title('Efficienza: Variazione Accuratezza vs Fine-Tuning Completo', fontsize=16)\n",
        "    plt.xticks(ticks=x_positions, labels=efficiency_labels, rotation=45, ha=\"right\")\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    for i, bar in enumerate(bars):\n",
        "        height = bar.get_height()\n",
        "        plt.text(x_positions[i], height, f'{height:.1f}%', ha='center', va='bottom' if height >= 0 else 'top')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"efficiency_accuracy_grouped.png\")\n",
        "\n",
        "    #Plot 2: Variazione F1-Score\n",
        "    plt.figure(figsize=(15, 6))\n",
        "    bars = plt.bar(x_positions, f1_change_data, color=colors, width=bar_width)\n",
        "    plt.axhline(y=0, color='black', linestyle='-', linewidth=1)\n",
        "    plt.ylabel('Variazione F1-Score (%) vs Baseline')\n",
        "    plt.title('Efficienza: Variazione F1-Score vs Fine-Tuning Completo', fontsize=16)\n",
        "    plt.xticks(ticks=x_positions, labels=efficiency_labels, rotation=45, ha=\"right\")\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    for i, bar in enumerate(bars):\n",
        "        height = bar.get_height()\n",
        "        plt.text(x_positions[i], height, f'{height:.1f}%', ha='center', va='bottom' if height >= 0 else 'top')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"efficiency_f1_score_grouped.png\")\n",
        "\n",
        "    #Plot 3: Risparmio Tempo Addestramento\n",
        "    plt.figure(figsize=(15, 6))\n",
        "    bars = plt.bar(x_positions, time_gain_data, color=colors, width=bar_width)\n",
        "    plt.axhline(y=0, color='black', linestyle='-', linewidth=1)\n",
        "    plt.ylabel('Risparmio Tempo Addestramento (%) vs Baseline')\n",
        "    plt.title('Efficienza: Risparmio Tempo vs Fine-Tuning Completo', fontsize=16)\n",
        "    plt.xticks(ticks=x_positions, labels=efficiency_labels, rotation=45, ha=\"right\")\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    for i, bar in enumerate(bars):\n",
        "        height = bar.get_height()\n",
        "        plt.text(x_positions[i], height, f'{height:.1f}%', ha='center', va='bottom')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"efficiency_time_grouped.png\")\n",
        "\n",
        "    #Plot 4: Risparmio Picco Memoria\n",
        "    plt.figure(figsize=(15, 6))\n",
        "    bars = plt.bar(x_positions, mem_gain_data, color=colors, width=bar_width)\n",
        "    plt.axhline(y=0, color='black', linestyle='-', linewidth=1)\n",
        "    plt.ylabel('Risparmio Picco Memoria (%) vs Baseline')\n",
        "    plt.title('Efficienza: Risparmio Memoria vs Fine-Tuning Completo', fontsize=16)\n",
        "    plt.xticks(ticks=x_positions, labels=efficiency_labels, rotation=45, ha=\"right\")\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    for i, bar in enumerate(bars):\n",
        "        height = bar.get_height()\n",
        "        plt.text(x_positions[i], height, f'{height:.1f}%', ha='center', va='bottom')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "rJTE2eFHykUe"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.12",
      "language": "python",
      "name": "py312"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}